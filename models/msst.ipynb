{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### README",
   "id": "81221e98587b9220"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model currently only has GRU active, the msst_classes file has the micro graphs turned off in the fusion module, and the only used features are the variants, not the exogenous covariates.",
   "id": "3fee037bd6c95243"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:04.865725Z",
     "start_time": "2025-11-14T09:24:00.746034Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import numpy as np\n",
    "from math import prod\n",
    "from torch.utils.data import Dataset\n",
    "import msst_classes \n",
    "from torch.utils.data import DataLoader, Subset"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Documents\\courses\\.venv\\lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "C:\\Documents\\courses\\.venv\\lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "C:\\Documents\\courses\\.venv\\lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(\n",
      "C:\\Documents\\courses\\.venv\\lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load State Data",
   "id": "65e6fa721fafaa64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.026067Z",
     "start_time": "2025-11-14T09:24:04.865725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state_df = pd.read_csv(\"../processed data/state_level/daily_covariates_state_level.csv\", parse_dates=['date'], dtype={'location': str})\n",
    "state_df.location = state_df.location.str.zfill(2)\n",
    "state_df.head()"
   ],
   "id": "640e30d6f0cac0e4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date location  people_vaccinated  people_fully_vaccinated  \\\n",
       "0 2021-01-01       01            53829.0                    272.0   \n",
       "1 2021-01-02       01            54052.0                    281.0   \n",
       "2 2021-01-03       01            55046.0                    284.0   \n",
       "3 2021-01-04       01            61092.0                    402.0   \n",
       "4 2021-01-05       01            69520.0                    844.0   \n",
       "\n",
       "   school_closing  workplace_closing  cancel_events  gatherings_restrictions  \\\n",
       "0             2.0                1.0            1.0                      0.0   \n",
       "1             2.0                1.0            1.0                      0.0   \n",
       "2             2.0                1.0            1.0                      0.0   \n",
       "3             2.0                1.0            1.0                      0.0   \n",
       "4             2.0                1.0            1.0                      0.0   \n",
       "\n",
       "   transport_closing  stay_home_restrictions  ...  population  Alpha  Beta  \\\n",
       "0                0.0                     1.0  ...     4903185    0.0   0.0   \n",
       "1                0.0                     1.0  ...     4903185    0.0   0.0   \n",
       "2                0.0                     1.0  ...     4903185    0.0   0.0   \n",
       "3                0.0                     1.0  ...     4903185    0.0   0.0   \n",
       "4                0.0                     1.0  ...     4903185    0.0   0.0   \n",
       "\n",
       "   Delta  Epsilon  Gamma  Iota  Omicron  deaths   Other  \n",
       "0    0.0      0.0    0.0   0.0      0.0      45  4521.0  \n",
       "1    0.0      0.0    0.0   0.0      0.0       0  3711.0  \n",
       "2    0.0      0.0    0.0   0.0      0.0       1  2476.0  \n",
       "3    0.0      0.0    0.0   0.0      0.0       5  2161.0  \n",
       "4    0.0      0.0    0.0   0.0      0.0       8  5498.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>people_vaccinated</th>\n",
       "      <th>people_fully_vaccinated</th>\n",
       "      <th>school_closing</th>\n",
       "      <th>workplace_closing</th>\n",
       "      <th>cancel_events</th>\n",
       "      <th>gatherings_restrictions</th>\n",
       "      <th>transport_closing</th>\n",
       "      <th>stay_home_restrictions</th>\n",
       "      <th>...</th>\n",
       "      <th>population</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Iota</th>\n",
       "      <th>Omicron</th>\n",
       "      <th>deaths</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>01</td>\n",
       "      <td>53829.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4903185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45</td>\n",
       "      <td>4521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>01</td>\n",
       "      <td>54052.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4903185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>01</td>\n",
       "      <td>55046.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4903185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>61092.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4903185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>01</td>\n",
       "      <td>69520.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4903185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5498.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.045587Z",
     "start_time": "2025-11-14T09:24:05.026067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state_covs = pd.read_csv(\"../processed data/state_level/state_level_characteristics.csv\", dtype={'state_fips':str}, index_col=0)\n",
    "state_covs.head()"
   ],
   "id": "b7ea126bb4902671",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  state_fips  Population  median_age  Income  Density_per_mile\n",
       "0         01     5157699        39.6   65560             101.0\n",
       "1         04     7582384        39.4   84700              65.0\n",
       "2         05     3088354        39.1   64840              59.0\n",
       "3         06    39431263        38.4  100600             250.0\n",
       "4         08     5957494        38.0  106500              57.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_fips</th>\n",
       "      <th>Population</th>\n",
       "      <th>median_age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Density_per_mile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>5157699</td>\n",
       "      <td>39.6</td>\n",
       "      <td>65560</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04</td>\n",
       "      <td>7582384</td>\n",
       "      <td>39.4</td>\n",
       "      <td>84700</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05</td>\n",
       "      <td>3088354</td>\n",
       "      <td>39.1</td>\n",
       "      <td>64840</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06</td>\n",
       "      <td>39431263</td>\n",
       "      <td>38.4</td>\n",
       "      <td>100600</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08</td>\n",
       "      <td>5957494</td>\n",
       "      <td>38.0</td>\n",
       "      <td>106500</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.085634Z",
     "start_time": "2025-11-14T09:24:05.045587Z"
    }
   },
   "cell_type": "code",
   "source": "state_df = state_df.merge(state_covs, left_on='location', right_on='state_fips', how='inner').drop(['population', 'deaths', 'state_fips'], axis=1)",
   "id": "dd995a6e3cdef7f4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.106035Z",
     "start_time": "2025-11-14T09:24:05.086152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state_fips_list = sorted(state_df['location'].unique())\n",
    "state_index = {fips: i for i, fips in enumerate(state_fips_list)}\n",
    "S = len(state_fips_list)"
   ],
   "id": "9dc47c224e81bb4a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.126067Z",
     "start_time": "2025-11-14T09:24:05.106035Z"
    }
   },
   "cell_type": "code",
   "source": "all_dates = pd.date_range(state_df['date'].min(), state_df['date'].max(), freq='D')",
   "id": "30b2d8de22546514",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.145693Z",
     "start_time": "2025-11-14T09:24:05.128066Z"
    }
   },
   "cell_type": "code",
   "source": "state_df = state_df.sort_values(['date', 'location'])",
   "id": "fb43a9be4f7c0736",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.175661Z",
     "start_time": "2025-11-14T09:24:05.145693Z"
    }
   },
   "cell_type": "code",
   "source": "state_df = state_df.set_index(['location', 'date'])",
   "id": "3c21314ed6966c8e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.195639Z",
     "start_time": "2025-11-14T09:24:05.175661Z"
    }
   },
   "cell_type": "code",
   "source": "variant_cols = ['Alpha', 'Beta', 'Delta', 'Epsilon', 'Gamma', 'Iota', 'Omicron', 'Other']",
   "id": "8a05c498fead8f49",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.215996Z",
     "start_time": "2025-11-14T09:24:05.195639Z"
    }
   },
   "cell_type": "code",
   "source": "state_df[variant_cols] /= 1000",
   "id": "ee6525f18f5bd0f7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.235662Z",
     "start_time": "2025-11-14T09:24:05.215996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# exo_cols = ['people_vaccinated', 'people_fully_vaccinated', 'school_closing',\n",
    "#        'workplace_closing', 'cancel_events', 'gatherings_restrictions',\n",
    "#        'transport_closing', 'stay_home_restrictions',\n",
    "#        'internal_movement_restrictions', 'international_movement_restrictions',\n",
    "#        'information_campaigns', 'testing_policy', 'contact_tracing',\n",
    "#        'facial_coverings', 'vaccination_policy', 'elderly_people_protection',\n",
    "#        'government_response_index', 'stringency_index',\n",
    "#        'containment_health_index', 'economic_support_index']\n",
    "# static_cols = ['Population',\n",
    "#        'median_age', 'Income', 'Density_per_mile']"
   ],
   "id": "199252ef9fb6bf73",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.255895Z",
     "start_time": "2025-11-14T09:24:05.236771Z"
    }
   },
   "cell_type": "code",
   "source": "# exo_cols = ['people_vaccinated', 'people_fully_vaccinated', 'stringency_index']",
   "id": "f788ddd60b2c2341",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.265749Z",
     "start_time": "2025-11-14T09:24:05.255895Z"
    }
   },
   "cell_type": "code",
   "source": "feature_cols = variant_cols",
   "id": "2812d7e5e44883d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.286056Z",
     "start_time": "2025-11-14T09:24:05.265749Z"
    }
   },
   "cell_type": "code",
   "source": "# feature_cols = variant_cols + exo_cols",
   "id": "cda56dfded2bbcda",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.305979Z",
     "start_time": "2025-11-14T09:24:05.286056Z"
    }
   },
   "cell_type": "code",
   "source": "# feature_cols = variant_cols + static_cols + exo_cols",
   "id": "db30eeff5b39a6c1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.375835Z",
     "start_time": "2025-11-14T09:24:05.305979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "T = len(all_dates)\n",
    "F_macro = len(feature_cols)\n",
    "X_state = np.zeros((T, S, F_macro), dtype=np.float32)\n",
    "\n",
    "for s_idx, s_fips in enumerate(state_fips_list):\n",
    "    sub = state_df.xs(s_fips, level='location')[feature_cols]\n",
    "    X_state[:, s_idx, :] = sub.to_numpy()\n"
   ],
   "id": "f60ba3fb6c781587",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build County Adjacency Matrix",
   "id": "57d979927a33c60d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.395550Z",
     "start_time": "2025-11-14T09:24:05.375835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../processed data/county level/county_adj_by_state.pkl', 'rb') as file:\n",
    "    adj_1 = pickle.load(file)"
   ],
   "id": "9abcb5adc077b1ac",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.416111Z",
     "start_time": "2025-11-14T09:24:05.395691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../processed data/county level/county_airport_weights_by_state.pkl', 'rb') as file:\n",
    "    adj_2 = pickle.load(file)"
   ],
   "id": "26a310a6e15ffaad",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.435902Z",
     "start_time": "2025-11-14T09:24:05.416111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../processed data/county level/county_highway_weights_by_state.pkl', 'rb') as file:\n",
    "    adj_3 = pickle.load(file)"
   ],
   "id": "1ee26c3cd2791be2",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.450910Z",
     "start_time": "2025-11-14T09:24:05.436903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "county_ids_dict = {}   # state_fips -> ordered list of county FIPS (strings or ints)\n",
    "county_adj_dict = {}   # state_fips -> np.ndarray (M_s x M_s)"
   ],
   "id": "9c58f8422c9879ae",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.476144Z",
     "start_time": "2025-11-14T09:24:05.452902Z"
    }
   },
   "cell_type": "code",
   "source": "state_fips_list = sorted(adj_1.keys())",
   "id": "aa0bffdda6a03abb",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.485962Z",
     "start_time": "2025-11-14T09:24:05.476144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_df(df):\n",
    "    arr = df.to_numpy(dtype=np.float32)\n",
    "    max_val = np.percentile(arr, 95)  # or arr.max()\n",
    "    if max_val > 0:\n",
    "        arr = arr / max_val\n",
    "    return arr"
   ],
   "id": "cc662e2cc0884795",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.585803Z",
     "start_time": "2025-11-14T09:24:05.486046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for s_fips in state_fips_list:\n",
    "    df1 = adj_1[s_fips]\n",
    "    df2 = adj_2.get(s_fips, None)          # may be None\n",
    "    df3 = adj_3.get(s_fips, None)          # may be None\n",
    "\n",
    "    # 1) Compute the union of county IDs present in any of the three\n",
    "    counties = set(df1.index)\n",
    "    if df2 is not None:\n",
    "        counties |= set(df2.index)\n",
    "    if df3 is not None:\n",
    "        counties |= set(df3.index)\n",
    "    counties = sorted(counties)\n",
    "\n",
    "    # 2) Align each DF to this county list; missing df gets all zeros\n",
    "    df1_al = df1.reindex(index=counties, columns=counties, fill_value=0)\n",
    "\n",
    "    if df2 is not None:\n",
    "        df2_al = df2.reindex(index=counties, columns=counties, fill_value=0)\n",
    "    else:\n",
    "        df2_al = pd.DataFrame(0.0, index=counties, columns=counties)\n",
    "\n",
    "    if df3 is not None:\n",
    "        df3_al = df3.reindex(index=counties, columns=counties, fill_value=0)\n",
    "    else:\n",
    "        df3_al = pd.DataFrame(0.0, index=counties, columns=counties)\n",
    "\n",
    "    # 3) Sum the three weight types\n",
    "    W1 = normalize_df(df1_al)\n",
    "    W2 = normalize_df(df2_al) if df2 is not None else np.zeros_like(W1)\n",
    "    W3 = normalize_df(df3_al) if df3 is not None else np.zeros_like(W1)\n",
    "    \n",
    "    # Option A: equal weight\n",
    "    A_s = W1 + W2 + W3\n",
    "\n",
    "    # 4) Save ordering + adjacency\n",
    "    county_ids_dict[s_fips] = counties   # this defines row/col order\n",
    "    county_adj_dict[s_fips] = A_s        # (M_s, M_s)"
   ],
   "id": "e6134bf3649021e9",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build global county graph",
   "id": "4375d29400c8585b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.605721Z",
     "start_time": "2025-11-14T09:24:05.586326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "county_fips_global = []   # global list of county FIPS\n",
    "state_of_county = []      # same length as county_fips_global\n",
    "\n",
    "# Also count total counties to size A_county_global later\n",
    "total_counties = 0\n",
    "for s_fips in state_fips_list:\n",
    "    counties_s = county_ids_dict[s_fips]\n",
    "    total_counties += len(counties_s)\n",
    "\n",
    "M = total_counties\n",
    "state_of_county = np.zeros(M, dtype=np.int64)\n",
    "\n",
    "# Fill county_fips_global + state_of_county and build A_county_global\n",
    "A_county_global = np.zeros((M, M), dtype=np.float32)\n",
    "\n",
    "offset = 0\n",
    "for s_fips in state_fips_list:\n",
    "    A_s = county_adj_dict[s_fips].astype(np.float32)\n",
    "    counties_s = county_ids_dict[s_fips]\n",
    "    n_s = len(counties_s)\n",
    "\n",
    "    # sanity check\n",
    "    assert A_s.shape == (n_s, n_s), f\"Adjacency size mismatch for state {s_fips}\"\n",
    "\n",
    "    # record county FIPS + state indices for these n_s counties\n",
    "    s_idx = state_index[s_fips]\n",
    "    for local_idx, c_fips in enumerate(counties_s):\n",
    "        global_idx = offset + local_idx\n",
    "        county_fips_global.append(c_fips)\n",
    "        state_of_county[global_idx] = s_idx\n",
    "\n",
    "    # place this state's adjacency in the block-diagonal\n",
    "    A_county_global[offset:offset+n_s, offset:offset+n_s] = A_s\n",
    "\n",
    "    offset += n_s\n",
    "\n",
    "# final sanity\n",
    "assert offset == M\n"
   ],
   "id": "43a52759fad6d9a8",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Building covariates",
   "id": "cc0b3d48a1aa5575"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:05.625934Z",
     "start_time": "2025-11-14T09:24:05.605721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "county_fips_global = [str(c) for c in county_fips_global]\n",
    "county_to_global = {c_fips: idx for idx, c_fips in enumerate(county_fips_global)}\n",
    "\n",
    "M = len(county_fips_global)\n",
    "T = len(all_dates)\n",
    "F_micro = len(variant_cols)\n"
   ],
   "id": "183bd7587435bb01",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:06.011147Z",
     "start_time": "2025-11-14T09:24:05.625934Z"
    }
   },
   "cell_type": "code",
   "source": "county_cases_daily = pd.read_parquet('../processed data/county level/daily_cases_by_county.parquet')",
   "id": "b9ce6f017157840a",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:12.776160Z",
     "start_time": "2025-11-14T09:24:06.013180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "county_cases_dict = dict()\n",
    "for state in state_fips_list:\n",
    "    df = county_cases_daily[county_cases_daily.state == state]\n",
    "    county_cases_dict[state] = df"
   ],
   "id": "31a0899b5f7a40b1",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:12.796248Z",
     "start_time": "2025-11-14T09:24:12.776160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# with open('../processed data/county level/rolled_county_cases.pkl', 'rb') as file:\n",
    "#     county_cases_dict = pickle.load(file)"
   ],
   "id": "bc8fc73f32a8b58f",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:12.816018Z",
     "start_time": "2025-11-14T09:24:12.797344Z"
    }
   },
   "cell_type": "code",
   "source": "county_cases_dict['06']",
   "id": "cba2fd549112968",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         fips       date state      Alpha  Beta  Delta     Epsilon  Gamma  \\\n",
       "116800  06001 2021-01-01    06  14.925956   0.0    0.0  328.006993    0.0   \n",
       "116801  06001 2021-01-02    06  17.707980   0.0    0.0  387.804754    0.0   \n",
       "116802  06001 2021-01-03    06  16.257089   0.0    0.0  379.206049    0.0   \n",
       "116803  06001 2021-01-04    06   5.860160   0.0    0.0  222.257275    0.0   \n",
       "116804  06001 2021-01-05    06   8.738730   0.0    0.0  334.351426    0.0   \n",
       "...       ...        ...   ...        ...   ...    ...         ...    ...   \n",
       "159865  06999 2022-12-27    06   0.000000   0.0    0.0    0.000000    0.0   \n",
       "159866  06999 2022-12-28    06   0.000000   0.0    0.0    0.000000    0.0   \n",
       "159867  06999 2022-12-29    06   0.000000   0.0    0.0    0.000000    0.0   \n",
       "159868  06999 2022-12-30    06   0.000000   0.0    0.0    0.000000    0.0   \n",
       "159869  06999 2022-12-31    06   0.000000   0.0    0.0    0.000000    0.0   \n",
       "\n",
       "        Iota  Omicron       Other  \n",
       "116800   0.0      0.0  542.067051  \n",
       "116801   0.0      0.0  637.487267  \n",
       "116802   0.0      0.0  604.536862  \n",
       "116803   0.0      0.0  326.882565  \n",
       "116804   0.0      0.0  482.909844  \n",
       "...      ...      ...         ...  \n",
       "159865   0.0      0.0    0.000000  \n",
       "159866   0.0      0.0    0.000000  \n",
       "159867   0.0      0.0    0.000000  \n",
       "159868   0.0      0.0    0.000000  \n",
       "159869   0.0      0.0    0.000000  \n",
       "\n",
       "[43070 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Iota</th>\n",
       "      <th>Omicron</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116800</th>\n",
       "      <td>06001</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>06</td>\n",
       "      <td>14.925956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>328.006993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>542.067051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116801</th>\n",
       "      <td>06001</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>06</td>\n",
       "      <td>17.707980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>387.804754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>637.487267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116802</th>\n",
       "      <td>06001</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>06</td>\n",
       "      <td>16.257089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.206049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>604.536862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116803</th>\n",
       "      <td>06001</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>06</td>\n",
       "      <td>5.860160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.257275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.882565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116804</th>\n",
       "      <td>06001</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>06</td>\n",
       "      <td>8.738730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.351426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>482.909844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159865</th>\n",
       "      <td>06999</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159866</th>\n",
       "      <td>06999</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159867</th>\n",
       "      <td>06999</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159868</th>\n",
       "      <td>06999</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159869</th>\n",
       "      <td>06999</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43070 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:17.785571Z",
     "start_time": "2025-11-14T09:24:12.816018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_county = np.zeros((T, M, F_micro), dtype=np.float32)\n",
    "\n",
    "for s_fips in state_fips_list:\n",
    "    if s_fips not in county_cases_dict:\n",
    "        # If a state has adjacency but no county time series -> stays all zeros\n",
    "        continue\n",
    "\n",
    "    df = county_cases_dict[s_fips].copy()\n",
    "    # ensure types & ordering\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['fips'] = df['fips'].astype(str)\n",
    "    df[variant_cols] /= 1000\n",
    "    # (optional) sanity: all counties from this state should be in county_ids_dict\n",
    "    # missing ones will just be ignored or raise a KeyError below\n",
    "    # assert set(df['county_fips'].unique()).issubset(set(county_ids_dict[s_fips]))\n",
    "\n",
    "    # group by county and fill each global row\n",
    "    for c_fips, group in df.groupby('fips'):\n",
    "        # skip counties that didn't make it into the adjacency for some reason\n",
    "        if c_fips not in county_to_global:\n",
    "            continue\n",
    "\n",
    "        g_idx = county_to_global[c_fips]\n",
    "\n",
    "        # index by date, select variant columns, align to all_dates\n",
    "        sub = (\n",
    "            group\n",
    "            .set_index('date')[variant_cols]\n",
    "            .reindex(all_dates)\n",
    "            .fillna(0.0)\n",
    "        )\n",
    "\n",
    "        X_county[:, g_idx, :] = sub.to_numpy(dtype=np.float32)\n"
   ],
   "id": "de8f430010402e86",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:17.805550Z",
     "start_time": "2025-11-14T09:24:17.785571Z"
    }
   },
   "cell_type": "code",
   "source": "X_state.shape",
   "id": "169af95fe681e8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 49, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:17.825968Z",
     "start_time": "2025-11-14T09:24:17.805550Z"
    }
   },
   "cell_type": "code",
   "source": "X_county.shape",
   "id": "8fa8e40489817633",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 3109, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build A_state",
   "id": "b9905592b26f320c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:17.845563Z",
     "start_time": "2025-11-14T09:24:17.825968Z"
    }
   },
   "cell_type": "code",
   "source": "state_airweights = pd.read_csv('../processed data/state_level/state_level_airport_weights.csv', index_col=0, dtype={'STATEFP':str})",
   "id": "4d04fb4248f5c303",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:17.865798Z",
     "start_time": "2025-11-14T09:24:17.846721Z"
    }
   },
   "cell_type": "code",
   "source": "state_borderweights = pd.read_csv('../processed data/state_level/state_level_border_weights.csv', index_col=0, dtype={'state_fips':str})",
   "id": "e53b6064648cf247",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:17.895589Z",
     "start_time": "2025-11-14T09:24:17.865798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state_highwayweights = pd.read_csv('../processed data/state_level/state_level_highway_weights.csv', index_col=0, dtype={'state_fips':str})\n",
    "state_highwayweights.index = state_highwayweights.columns = [fips.zfill(2) for fips in state_highwayweights.columns.to_list()]\n",
    "state_highwayweights = state_highwayweights.reindex(index=state_fips_list,\n",
    "                                    columns=state_fips_list,\n",
    "                                    fill_value=0.0)"
   ],
   "id": "fa56e89c8bc80795",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:17.915691Z",
     "start_time": "2025-11-14T09:24:17.895589Z"
    }
   },
   "cell_type": "code",
   "source": "state_airweights.index.to_list() == state_borderweights.index.to_list() == state_highwayweights.index.to_list()",
   "id": "2b6a44dbaca248d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:17.935694Z",
     "start_time": "2025-11-14T09:24:17.915691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "W1 = normalize_df(state_airweights)\n",
    "W2 = normalize_df(state_borderweights) \n",
    "W3 = normalize_df(state_highwayweights) \n",
    "A_state = W1 + W2 + W3"
   ],
   "id": "7c5ce36110e41747",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:17.950781Z",
     "start_time": "2025-11-14T09:24:17.936781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "v_out = len(variant_cols)\n",
    "target_variant_indices = [feature_cols.index(v) for v in variant_cols]"
   ],
   "id": "8862aa0fb3f72720",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train",
   "id": "f034ea870e5f80e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:17.985931Z",
     "start_time": "2025-11-14T09:24:17.951782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_len = 14\n",
    "horizon = 7\n",
    "\n",
    "dataset = msst_classes.EpidemicDataset(\n",
    "    X_state=X_state,\n",
    "    X_county=X_county,\n",
    "    input_len=input_len,\n",
    "    horizon=horizon,\n",
    "    target_variant_indices=target_variant_indices,\n",
    ")\n",
    "\n",
    "N = len(dataset)\n",
    "train_ratio = 0.8\n",
    "N_train = int(N * train_ratio)\n",
    "train_indices = np.arange(0, N_train)\n",
    "val_indices = np.arange(N_train, N)\n",
    "\n",
    "# tiny_indices = np.arange(0, 10)   # or even 0..4\n",
    "# train_ds = Subset(dataset, tiny_indices)\n",
    "# train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "train_ds = Subset(dataset, train_indices)\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "val_ds   = Subset(dataset, val_indices)\n",
    "val_loader   = DataLoader(val_ds, batch_size=1, shuffle=False)\n"
   ],
   "id": "18907e5b04d7e77a",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:18.085712Z",
     "start_time": "2025-11-14T09:24:17.985931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "hidden_gcn_macro = 64\n",
    "hidden_gcn_micro = 32\n",
    "macro_out_dim = 32\n",
    "micro_out_dim = 32\n",
    "hidden_gru = 64\n",
    "\n",
    "v_out = len(target_variant_indices)\n",
    "\n",
    "### GRU Only\n",
    "# model = msst_classes.GRUOnly(F_macro, hidden_gru=32, horizon=horizon, v_out=v_out).to(device)\n",
    "\n",
    "\n",
    "### GCN+MacroGCN concatenated\n",
    "# macro_gcn = msst_classes.MacroGCN(\n",
    "#     in_dim=F_macro,\n",
    "#     hidden_dim=hidden_gcn,\n",
    "#     out_dim=gcn_out_dim,\n",
    "#     A_state=A_state\n",
    "# ).to(device)\n",
    "# \n",
    "# model = msst_classes.MacroGCNGRUResidualSkip(\n",
    "#     macro_gcn=macro_gcn,\n",
    "#     in_dim=F_macro,\n",
    "#     gcn_out_dim=gcn_out_dim,\n",
    "#     hidden_gru=hidden_gru,\n",
    "#     horizon=horizon,\n",
    "#     v_out=v_out\n",
    "# ).to(device)\n",
    "\n",
    "### Macro+Micro+GRU\n",
    "macro_gcn = msst_classes.MacroGCN(\n",
    "    in_dim=F_macro,\n",
    "    hidden_dim=hidden_gcn_macro,\n",
    "    out_dim=macro_out_dim,\n",
    "    A_state=A_state\n",
    ").to(device)\n",
    "\n",
    "micro_gcn = msst_classes.MicroGCN(\n",
    "    in_dim=F_micro,\n",
    "    hidden_dim=hidden_gcn_micro,\n",
    "    out_dim=micro_out_dim,\n",
    "    A_county_global=A_county_global,\n",
    "    state_of_county=state_of_county  # length M, 0..S-1\n",
    ").to(device)\n",
    "\n",
    "model = msst_classes.MacroMicroGCNGRUResidual(\n",
    "    macro_gcn=macro_gcn,\n",
    "    micro_gcn=micro_gcn,\n",
    "    in_dim_state=F_macro,\n",
    "    macro_out_dim=macro_out_dim,\n",
    "    micro_out_dim=micro_out_dim,\n",
    "    hidden_gru=hidden_gru,\n",
    "    horizon=horizon,\n",
    "    v_out=len(variant_cols),\n",
    ").to(device)\n"
   ],
   "id": "3b13d6d8758decfc",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T09:24:18.095876Z",
     "start_time": "2025-11-14T09:24:18.085712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "loss_fn = nn.MSELoss()\n"
   ],
   "id": "e2a21c15a634f98e",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:07:31.051369Z",
     "start_time": "2025-11-14T09:24:18.095876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for X_state_seq, X_county_seq, y_resid_true, baseline_full in train_loader:\n",
    "    \n",
    "        # Remove batch dimension (batch_size=1)\n",
    "        X_state_seq   = X_state_seq.squeeze(0).to(device)      # (T_in, S, F_macro)\n",
    "        X_county_seq  = X_county_seq.squeeze(0).to(device)     # (T_in, M, F_micro)\n",
    "        y_resid_true  = y_resid_true.squeeze(0).to(device)     # (S, horizon, v_out)\n",
    "        baseline_full = baseline_full.squeeze(0).to(device)    # (S, horizon, v_out)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Model predicts residuals\n",
    "        y_resid_pred = model(X_state_seq, X_county_seq)        # (S, horizon, v_out)\n",
    "    \n",
    "        loss = loss_fn(y_resid_pred, y_resid_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in val_loader:\n",
    "            X_state_seq = X_state_seq.squeeze(0).to(device)\n",
    "            X_county_seq = X_county_seq.squeeze(0).to(device)\n",
    "            y_resid_true = y_resid_true.squeeze(0).to(device)\n",
    "\n",
    "            y_resid_pred = model(X_state_seq, X_county_seq)         # (S, H, V)\n",
    "            y_pred_raw = y_resid_pred + baseline_full.to(device)    # (S, H, V)\n",
    "            y_true_raw = y_resid_true + baseline_full.to(device)    # or store y_raw separately\n",
    "            loss = loss_fn(y_pred_raw, y_true_raw)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    mean_train = np.mean(train_losses) if train_losses else float(\"nan\")\n",
    "    mean_val = np.mean(val_losses) if val_losses else float(\"nan\")\n",
    "    print(f\"Epoch {epoch:03d}: train_loss={mean_train:.4f}, val_loss={mean_val:.4f}\")\n"
   ],
   "id": "578aa1b8d27828fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: train_loss=2.8399, val_loss=0.9475\n",
      "Epoch 002: train_loss=2.7402, val_loss=0.8493\n",
      "Epoch 003: train_loss=2.5107, val_loss=0.8152\n",
      "Epoch 004: train_loss=2.2919, val_loss=0.7393\n",
      "Epoch 005: train_loss=2.1590, val_loss=0.6823\n",
      "Epoch 006: train_loss=2.0443, val_loss=0.6306\n",
      "Epoch 007: train_loss=1.9074, val_loss=0.6450\n",
      "Epoch 008: train_loss=1.8332, val_loss=0.5874\n",
      "Epoch 009: train_loss=1.7413, val_loss=0.5861\n",
      "Epoch 010: train_loss=1.6950, val_loss=0.7284\n",
      "Epoch 011: train_loss=1.5850, val_loss=0.5226\n",
      "Epoch 012: train_loss=1.5139, val_loss=0.5305\n",
      "Epoch 013: train_loss=1.4690, val_loss=0.5234\n",
      "Epoch 014: train_loss=1.4105, val_loss=0.5955\n",
      "Epoch 015: train_loss=1.4192, val_loss=0.5279\n",
      "Epoch 016: train_loss=1.2693, val_loss=0.4929\n",
      "Epoch 017: train_loss=1.2959, val_loss=0.4877\n",
      "Epoch 018: train_loss=1.1899, val_loss=0.5904\n",
      "Epoch 019: train_loss=1.1540, val_loss=0.5131\n",
      "Epoch 020: train_loss=1.0841, val_loss=0.4749\n",
      "Epoch 021: train_loss=1.0296, val_loss=0.5455\n",
      "Epoch 022: train_loss=1.0429, val_loss=0.5645\n",
      "Epoch 023: train_loss=0.9905, val_loss=0.5437\n",
      "Epoch 024: train_loss=0.9161, val_loss=0.5141\n",
      "Epoch 025: train_loss=0.9265, val_loss=0.5964\n",
      "Epoch 026: train_loss=0.9683, val_loss=0.5195\n",
      "Epoch 027: train_loss=0.9048, val_loss=0.5469\n",
      "Epoch 028: train_loss=0.8171, val_loss=0.5206\n",
      "Epoch 029: train_loss=0.7899, val_loss=0.5505\n",
      "Epoch 030: train_loss=0.9149, val_loss=0.5296\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Eval (Daily)",
   "id": "71e48700f918d03c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:07:31.091920Z",
     "start_time": "2025-11-14T11:07:31.053467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Global RMSE by variant, then summed\n",
    "def overall_rmse_model_from_residual(model, loader, device, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    Global RMSE for the model in raw daily-count units.\n",
    "\n",
    "    Assumes:\n",
    "      - loader yields (X_state_seq, X_county_seq, y_resid_true, baseline_full)\n",
    "      - model outputs y_resid_pred with same shape as y_resid_true: (S, H, V)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sum_sq = 0.0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            X_state_seq   = X_state_seq.squeeze(0).to(device)\n",
    "            X_county_seq  = X_county_seq.squeeze(0).to(device)\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            y_resid_pred = model(X_state_seq, X_county_seq)     # (S, H, V)\n",
    "\n",
    "            # diff in raw units (baseline cancels in residual space)\n",
    "            diff = (y_resid_pred - y_resid_true) * case_scale   # (S, H, V)\n",
    "            se = diff ** 2\n",
    "\n",
    "            sum_sq += se.sum().item()\n",
    "            count  += se.numel()\n",
    "\n",
    "    return (sum_sq / count) ** 0.5\n",
    "\n",
    "def overall_rmse_ma_baseline_from_residual(loader, device, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    Global RMSE for the MA baseline in raw daily-count units.\n",
    "\n",
    "    Baseline: y_resid_pred = 0  => forecast = baseline_full (raw space).\n",
    "    \"\"\"\n",
    "    sum_sq = 0.0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            y_resid_true = y_resid_true.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            # diff_raw = 0 - y_resid_true, scaled back\n",
    "            diff = (-y_resid_true) * case_scale                 # (S, H, V)\n",
    "            se = diff ** 2\n",
    "\n",
    "            sum_sq += se.sum().item()\n",
    "            count  += se.numel()\n",
    "\n",
    "    return (sum_sq / count) ** 0.5\n",
    "\n",
    "def overall_rmse_last_value_baseline_from_residual(loader, device, target_variant_indices, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    Global RMSE for the last-value baseline in raw daily-count units.\n",
    "\n",
    "    Baseline: for each state & variant, predict all H future days equal to\n",
    "    the last observed daily count in the input window.\n",
    "\n",
    "    Assumes loader yields (X_state_seq, X_county_seq, y_resid_true, baseline_full),\n",
    "    and X_state_seq includes variant columns at indices target_variant_indices.\n",
    "    \"\"\"\n",
    "    target_variant_indices = torch.as_tensor(\n",
    "        target_variant_indices, dtype=torch.long, device=device\n",
    "    )\n",
    "\n",
    "    sum_sq = 0.0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            X_state_seq   = X_state_seq.squeeze(0).to(device)    # (T_in, S, F_macro)\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)   # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)  # (S, H, V)\n",
    "\n",
    "            # True raw future counts\n",
    "            y_true_raw = y_resid_true + baseline_full            # (S, H, V)\n",
    "\n",
    "            T_in, S, F_macro = X_state_seq.shape\n",
    "            H = y_true_raw.shape[1]\n",
    "            V = y_true_raw.shape[2]\n",
    "\n",
    "            # Last observed daily counts from input window\n",
    "            last_state = X_state_seq[-1]                         # (S, F_macro)\n",
    "            last_targets = last_state[:, target_variant_indices] # (S, V)\n",
    "\n",
    "            # Repeat across horizon\n",
    "            last_full = last_targets.unsqueeze(1).expand(S, H, V)  # (S, H, V)\n",
    "\n",
    "            diff = (last_full - y_true_raw) * case_scale         # (S, H, V)\n",
    "            se = diff ** 2\n",
    "\n",
    "            sum_sq += se.sum().item()\n",
    "            count  += se.numel()\n",
    "\n",
    "    return (sum_sq / count) ** 0.5\n"
   ],
   "id": "390ff7a795155f4f",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:07:31.132158Z",
     "start_time": "2025-11-14T11:07:31.112049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### RMSE per day\n",
    "def rmse_by_day_model(model, loader, device, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    RMSE by forecast day for the model, in *raw* daily count units.\n",
    "\n",
    "    Assumes loader yields:\n",
    "        (X_state_seq, X_county_seq, y_resid_true, baseline_full)\n",
    "    and model outputs y_resid_pred with same shape as y_resid_true: (S, H, V).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sum_sq_per_day = None   # (H,)\n",
    "    count_per_day = None    # (H,)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            # Remove batch dim (batch_size=1)\n",
    "            X_state_seq   = X_state_seq.squeeze(0).to(device)\n",
    "            X_county_seq  = X_county_seq.squeeze(0).to(device)\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)  # (S, H, V)\n",
    "\n",
    "            y_resid_pred = model(X_state_seq, X_county_seq)    # (S, H, V)\n",
    "\n",
    "            # difference in raw units (baseline cancels out)\n",
    "            diff = (y_resid_pred - y_resid_true) * case_scale   # (S, H, V)\n",
    "            se = diff ** 2                                      # (S, H, V)\n",
    "\n",
    "            S, H, V = se.shape\n",
    "            se_day = se.sum(dim=(0, 2))                         # (H,) sum over states & variants\n",
    "            n_day  = S * V                                      # per window\n",
    "\n",
    "            if sum_sq_per_day is None:\n",
    "                sum_sq_per_day = se_day.cpu()\n",
    "                count_per_day  = torch.full((H,), n_day, dtype=torch.long)\n",
    "            else:\n",
    "                sum_sq_per_day += se_day.cpu()\n",
    "                count_per_day  += n_day\n",
    "\n",
    "    mse_per_day = sum_sq_per_day / count_per_day\n",
    "    rmse_per_day = torch.sqrt(mse_per_day).numpy()\n",
    "    return rmse_per_day\n",
    "\n",
    "def rmse_by_day_ma_baseline(loader, device, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    RMSE by forecast day for the MA baseline built into the Dataset.\n",
    "    Baseline: y_resid_pred = 0  => forecast = baseline_full (in raw space).\n",
    "\n",
    "    Uses y_resid_true only; baseline cancels in residual space.\n",
    "    \"\"\"\n",
    "    sum_sq_per_day = None\n",
    "    count_per_day = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            y_resid_true = y_resid_true.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            # diff_raw = 0 - y_resid_true, scaled back\n",
    "            diff = (-y_resid_true) * case_scale                 # (S, H, V)\n",
    "            se = diff ** 2\n",
    "\n",
    "            S, H, V = se.shape\n",
    "            se_day = se.sum(dim=(0, 2))                         # (H,)\n",
    "            n_day  = S * V\n",
    "\n",
    "            if sum_sq_per_day is None:\n",
    "                sum_sq_per_day = se_day.cpu()\n",
    "                count_per_day  = torch.full((H,), n_day, dtype=torch.long)\n",
    "            else:\n",
    "                sum_sq_per_day += se_day.cpu()\n",
    "                count_per_day  += n_day\n",
    "\n",
    "    mse_per_day = sum_sq_per_day / count_per_day\n",
    "    rmse_per_day = torch.sqrt(mse_per_day).numpy()\n",
    "    return rmse_per_day\n",
    "\n",
    "def rmse_by_day_last_value_baseline_from_residual(loader, device, target_variant_indices, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    RMSE by forecast day for the last-value baseline in *raw* daily counts.\n",
    "\n",
    "    Baseline: for each state & variant, predict all H future days equal to\n",
    "    the last observed daily count in the input window.\n",
    "\n",
    "    Assumes loader yields (X_state_seq, X_county_seq, y_resid_true, baseline_full),\n",
    "    where X_state_seq includes the variant columns at indices target_variant_indices.\n",
    "    \"\"\"\n",
    "    target_variant_indices = torch.as_tensor(\n",
    "        target_variant_indices, dtype=torch.long, device=device\n",
    "    )\n",
    "\n",
    "    sum_sq_per_day = None\n",
    "    count_per_day = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            X_state_seq   = X_state_seq.squeeze(0).to(device)    # (T_in, S, F_macro)\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)   # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)  # (S, H, V)\n",
    "\n",
    "            # Reconstruct true raw future counts\n",
    "            y_true_raw = y_resid_true + baseline_full            # (S, H, V)\n",
    "\n",
    "            T_in, S, F_macro = X_state_seq.shape\n",
    "            H = y_true_raw.shape[1]\n",
    "            V = y_true_raw.shape[2]\n",
    "\n",
    "            # Last observed daily counts from input window\n",
    "            last_state = X_state_seq[-1]                         # (S, F_macro)\n",
    "            last_targets = last_state[:, target_variant_indices] # (S, V)\n",
    "\n",
    "            # Repeat across horizon\n",
    "            last_full = last_targets.unsqueeze(1).expand(S, H, V)  # (S, H, V)\n",
    "\n",
    "            # diff in raw units\n",
    "            diff = (last_full - y_true_raw) * case_scale         # (S, H, V)\n",
    "            se = diff ** 2\n",
    "\n",
    "            se_day = se.sum(dim=(0, 2))                          # (H,)\n",
    "            n_day  = S * V\n",
    "\n",
    "            if sum_sq_per_day is None:\n",
    "                sum_sq_per_day = se_day.cpu()\n",
    "                count_per_day  = torch.full((H,), n_day, dtype=torch.long)\n",
    "            else:\n",
    "                sum_sq_per_day += se_day.cpu()\n",
    "                count_per_day  += n_day\n",
    "\n",
    "    mse_per_day = sum_sq_per_day / count_per_day\n",
    "    rmse_per_day = torch.sqrt(mse_per_day).numpy()\n",
    "    return rmse_per_day\n"
   ],
   "id": "7868af65e8d9d2ac",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:19:39.366211Z",
     "start_time": "2025-11-14T11:19:39.350703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Global MAPE\n",
    "def overall_mape_model_from_residual(model, loader, device, case_scale=1.0, min_cases=0):\n",
    "    \"\"\"\n",
    "    Global MAPE (%) for the model in raw daily-count units.\n",
    "\n",
    "    Assumes loader yields:\n",
    "        (X_state_seq, X_county_seq, y_resid_true, baseline_full)\n",
    "    and model outputs y_resid_pred with shape (S, H, V).\n",
    "\n",
    "    MAPE is computed over all state×day×variant positions where y_true_raw != 0.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sum_pct = 0.0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            X_state_seq   = X_state_seq.squeeze(0).to(device)\n",
    "            X_county_seq  = X_county_seq.squeeze(0).to(device)\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)    # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            y_resid_pred = model(X_state_seq, X_county_seq)       # (S, H, V)\n",
    "\n",
    "            # Raw counts\n",
    "            y_true_raw = (y_resid_true + baseline_full) * case_scale\n",
    "            y_hat_raw  = (y_resid_pred + baseline_full) * case_scale\n",
    "\n",
    "            diff_abs = (y_hat_raw - y_true_raw).abs()\n",
    "            denom = y_true_raw.abs()\n",
    "\n",
    "            mask = denom > min_cases\n",
    "            if mask.any():\n",
    "                sum_pct += (diff_abs[mask] / denom[mask]).sum().item()\n",
    "                count   += mask.sum().item()\n",
    "\n",
    "    if count == 0:\n",
    "        return np.nan\n",
    "    return 100.0 * (sum_pct / count)\n",
    "\n",
    "def overall_mape_ma_baseline_from_residual(loader, device, case_scale=1.0, min_cases=0):\n",
    "    \"\"\"\n",
    "    Global MAPE (%) for the MA baseline in raw daily-count units.\n",
    "\n",
    "    Baseline: forecast_raw = baseline_full * case_scale.\n",
    "    \"\"\"\n",
    "    sum_pct = 0.0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)    # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            y_true_raw = (y_resid_true + baseline_full) * case_scale\n",
    "            y_hat_raw  = baseline_full * case_scale\n",
    "\n",
    "            diff_abs = (y_hat_raw - y_true_raw).abs()\n",
    "            denom = y_true_raw.abs()\n",
    "\n",
    "            mask = denom > min_cases\n",
    "            if mask.any():\n",
    "                sum_pct += (diff_abs[mask] / denom[mask]).sum().item()\n",
    "                count   += mask.sum().item()\n",
    "\n",
    "    if count == 0:\n",
    "        return np.nan\n",
    "    return 100.0 * (sum_pct / count)\n",
    "\n",
    "def overall_mape_last_value_baseline_from_residual(loader, device, target_variant_indices, case_scale=1.0, min_cases=0):\n",
    "    \"\"\"\n",
    "    Global MAPE (%) for the last-value baseline in raw daily-count units.\n",
    "\n",
    "    Baseline: for each state & variant, predict all H future days equal to\n",
    "    the last observed daily count in the input window.\n",
    "\n",
    "    Assumes:\n",
    "      - loader yields (X_state_seq, X_county_seq, y_resid_true, baseline_full)\n",
    "      - X_state_seq includes variant columns at indices target_variant_indices.\n",
    "    \"\"\"\n",
    "    target_variant_indices = torch.as_tensor(\n",
    "        target_variant_indices, dtype=torch.long, device=device\n",
    "    )\n",
    "\n",
    "    sum_pct = 0.0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            X_state_seq   = X_state_seq.squeeze(0).to(device)     # (T_in, S, F_macro)\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)    # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            # True raw future counts\n",
    "            y_true_raw = (y_resid_true + baseline_full) * case_scale  # (S, H, V)\n",
    "\n",
    "            T_in, S, F_macro = X_state_seq.shape\n",
    "            H = y_true_raw.shape[1]\n",
    "            V = y_true_raw.shape[2]\n",
    "\n",
    "            # Last observed daily counts for the variants of interest\n",
    "            last_state = X_state_seq[-1]                          # (S, F_macro)\n",
    "            last_targets = last_state[:, target_variant_indices]  # (S, V)\n",
    "\n",
    "            # Repeat across horizon\n",
    "            y_hat_raw = last_targets.unsqueeze(1).expand(S, H, V) * case_scale  # (S, H, V)\n",
    "\n",
    "            diff_abs = (y_hat_raw - y_true_raw).abs()\n",
    "            denom = y_true_raw.abs()\n",
    "\n",
    "            mask = denom > min_cases\n",
    "            if mask.any():\n",
    "                sum_pct += (diff_abs[mask] / denom[mask]).sum().item()\n",
    "                count   += mask.sum().item()\n",
    "\n",
    "    if count == 0:\n",
    "        return np.nan\n",
    "    return 100.0 * (sum_pct / count)\n"
   ],
   "id": "24d8cb38d0823515",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:30:33.282336Z",
     "start_time": "2025-11-14T11:30:33.266708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### RMSE for total cases \n",
    "def overall_rmse_model_total_from_residual(model, loader, device, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    Global RMSE (raw units) for the MODEL on TOTAL daily cases.\n",
    "\n",
    "    Steps per batch:\n",
    "      - y_resid_true, baseline_full -> reconstruct per-variant true counts\n",
    "      - model(...) -> per-variant residual preds -> per-variant pred counts\n",
    "      - sum over variants -> totals\n",
    "      - compute RMSE over all states × horizon\n",
    "\n",
    "    Assumes loader yields:\n",
    "      (X_state_seq, X_county_seq, y_resid_true, baseline_full)\n",
    "    with shapes:\n",
    "      y_resid_true: (1, S, H, V) or (S, H, V) before squeeze\n",
    "      baseline_full: same\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sum_sq = 0.0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            X_state_seq   = X_state_seq.squeeze(0).to(device)\n",
    "            X_county_seq  = X_county_seq.squeeze(0).to(device)\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)    # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            # Model residual preds\n",
    "            y_resid_pred = model(X_state_seq, X_county_seq)       # (S, H, V)\n",
    "\n",
    "            # Reconstruct raw per-variant counts\n",
    "            y_true_raw = (y_resid_true + baseline_full) * case_scale  # (S, H, V)\n",
    "            y_hat_raw  = (y_resid_pred + baseline_full) * case_scale  # (S, H, V)\n",
    "\n",
    "            # Sum over variants to get totals\n",
    "            y_true_total = y_true_raw.sum(dim=2)  # (S, H)\n",
    "            y_hat_total  = y_hat_raw.sum(dim=2)   # (S, H)\n",
    "\n",
    "            diff = y_hat_total - y_true_total     # (S, H)\n",
    "            se = diff ** 2\n",
    "\n",
    "            sum_sq += se.sum().item()\n",
    "            count  += se.numel()\n",
    "\n",
    "    return (sum_sq / count) ** 0.5\n",
    "\n",
    "def overall_rmse_ma_total_from_residual(loader, device, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    Global RMSE (raw units) for the MA baseline on TOTAL daily cases.\n",
    "\n",
    "    Baseline per variant: forecast_raw = baseline_full * case_scale.\n",
    "    Totals: sum over variants.\n",
    "    \"\"\"\n",
    "    sum_sq = 0.0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)    # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            # True per-variant raw counts\n",
    "            y_true_raw = (y_resid_true + baseline_full) * case_scale  # (S, H, V)\n",
    "            # Baseline per-variant raw preds\n",
    "            y_hat_raw  = baseline_full * case_scale                   # (S, H, V)\n",
    "\n",
    "            y_true_total = y_true_raw.sum(dim=2)  # (S, H)\n",
    "            y_hat_total  = y_hat_raw.sum(dim=2)   # (S, H)\n",
    "\n",
    "            diff = y_hat_total - y_true_total\n",
    "            se = diff ** 2\n",
    "\n",
    "            sum_sq += se.sum().item()\n",
    "            count  += se.numel()\n",
    "\n",
    "    return (sum_sq / count) ** 0.5\n",
    "\n",
    "def overall_rmse_last_total_from_residual(loader, device, target_variant_indices, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    Global RMSE (raw units) for the last-value baseline on TOTAL daily cases.\n",
    "\n",
    "    Baseline: for each state,\n",
    "      - take last observed per-variant daily counts from input window,\n",
    "      - sum over variants to get a total,\n",
    "      - predict that same total for all H forecast days.\n",
    "\n",
    "    Assumes:\n",
    "      - loader yields (X_state_seq, X_county_seq, y_resid_true, baseline_full)\n",
    "      - X_state_seq includes variant columns at indices target_variant_indices.\n",
    "    \"\"\"\n",
    "    target_variant_indices = torch.as_tensor(\n",
    "        target_variant_indices, dtype=torch.long, device=device\n",
    "    )\n",
    "\n",
    "    sum_sq = 0.0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            X_state_seq   = X_state_seq.squeeze(0).to(device)     # (T_in, S, F_macro)\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)    # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            # True per-variant raw counts\n",
    "            y_true_raw = (y_resid_true + baseline_full) * case_scale  # (S, H, V)\n",
    "            y_true_total = y_true_raw.sum(dim=2)                      # (S, H)\n",
    "\n",
    "            T_in, S, F_macro = X_state_seq.shape\n",
    "            H = y_true_total.shape[1]\n",
    "            V = y_true_raw.shape[2]\n",
    "\n",
    "            # Last observed per-variant daily counts from input window\n",
    "            last_state = X_state_seq[-1]                              # (S, F_macro)\n",
    "            last_targets = last_state[:, target_variant_indices]      # (S, V)\n",
    "            last_targets_raw = last_targets * case_scale              # (S, V)\n",
    "\n",
    "            # Total last-value per state\n",
    "            last_total = last_targets_raw.sum(dim=1)                  # (S,)\n",
    "\n",
    "            # Repeat across horizon\n",
    "            y_hat_total = last_total.unsqueeze(1).expand(S, H)        # (S, H)\n",
    "\n",
    "            diff = y_hat_total - y_true_total\n",
    "            se = diff ** 2\n",
    "\n",
    "            sum_sq += se.sum().item()\n",
    "            count  += se.numel()\n",
    "\n",
    "    return (sum_sq / count) ** 0.5\n"
   ],
   "id": "e999003866fd97a0",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:37:02.323652Z",
     "start_time": "2025-11-14T11:37:02.295514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### RMSE by state for total cases\n",
    "def rmse_by_state_total_model_from_residual(model, loader, device, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    Per-state RMSE (raw units) for the MODEL on TOTAL daily cases.\n",
    "\n",
    "    Returns: np.ndarray of shape (S,), where S is the #states, in the\n",
    "    same order as your state dimension in X_state_seq / y_resid_true.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sum_sq_state = None\n",
    "    count_state = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            X_state_seq   = X_state_seq.squeeze(0).to(device)\n",
    "            X_county_seq  = X_county_seq.squeeze(0).to(device)\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)    # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            S, H, V = y_resid_true.shape\n",
    "            if sum_sq_state is None:\n",
    "                sum_sq_state = torch.zeros(S, device=device)\n",
    "                count_state  = torch.zeros(S, device=device)\n",
    "\n",
    "            # Model residual preds\n",
    "            y_resid_pred = model(X_state_seq, X_county_seq)       # (S, H, V)\n",
    "\n",
    "            # Raw per-variant counts\n",
    "            y_true_raw = (y_resid_true + baseline_full) * case_scale  # (S, H, V)\n",
    "            y_hat_raw  = (y_resid_pred + baseline_full) * case_scale  # (S, H, V)\n",
    "\n",
    "            # Totals per state & horizon\n",
    "            y_true_total = y_true_raw.sum(dim=2)  # (S, H)\n",
    "            y_hat_total  = y_hat_raw.sum(dim=2)   # (S, H)\n",
    "\n",
    "            diff = y_hat_total - y_true_total     # (S, H)\n",
    "            se = diff ** 2                        # (S, H)\n",
    "\n",
    "            sum_sq_state += se.sum(dim=1)         # sum over horizon -> (S,)\n",
    "            count_state  += H\n",
    "\n",
    "    rmse_state = torch.sqrt(sum_sq_state / count_state.clamp(min=1)).cpu().numpy()\n",
    "    return rmse_state\n",
    "\n",
    "def rmse_by_state_total_ma_from_residual(loader, device, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    Per-state RMSE (raw units) for the MA baseline on TOTAL daily cases.\n",
    "    \"\"\"\n",
    "    sum_sq_state = None\n",
    "    count_state = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)    # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            S, H, V = y_resid_true.shape\n",
    "            if sum_sq_state is None:\n",
    "                sum_sq_state = torch.zeros(S, device=device)\n",
    "                count_state  = torch.zeros(S, device=device)\n",
    "\n",
    "            # Raw per-variant counts\n",
    "            y_true_raw = (y_resid_true + baseline_full) * case_scale  # (S, H, V)\n",
    "            y_hat_raw  = baseline_full * case_scale                   # (S, H, V)\n",
    "\n",
    "            y_true_total = y_true_raw.sum(dim=2)  # (S, H)\n",
    "            y_hat_total  = y_hat_raw.sum(dim=2)   # (S, H)\n",
    "\n",
    "            diff = y_hat_total - y_true_total\n",
    "            se = diff ** 2\n",
    "\n",
    "            sum_sq_state += se.sum(dim=1)\n",
    "            count_state  += H\n",
    "\n",
    "    rmse_state = torch.sqrt(sum_sq_state / count_state.clamp(min=1)).cpu().numpy()\n",
    "    return rmse_state\n",
    "\n",
    "def rmse_by_state_total_last_from_residual(loader, device, target_variant_indices, case_scale=1.0):\n",
    "    \"\"\"\n",
    "    Per-state RMSE (raw units) for the last-value baseline on TOTAL daily cases.\n",
    "\n",
    "    Baseline: for each state, total forecast = sum of last observed per-variant\n",
    "    daily counts in the input window, repeated across all H forecast days.\n",
    "    \"\"\"\n",
    "    target_variant_indices = torch.as_tensor(\n",
    "        target_variant_indices, dtype=torch.long, device=device\n",
    "    )\n",
    "\n",
    "    sum_sq_state = None\n",
    "    count_state = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_state_seq, X_county_seq, y_resid_true, baseline_full in loader:\n",
    "            X_state_seq   = X_state_seq.squeeze(0).to(device)     # (T_in, S, F_macro)\n",
    "            y_resid_true  = y_resid_true.squeeze(0).to(device)    # (S, H, V)\n",
    "            baseline_full = baseline_full.squeeze(0).to(device)   # (S, H, V)\n",
    "\n",
    "            S, H, V = y_resid_true.shape\n",
    "            if sum_sq_state is None:\n",
    "                sum_sq_state = torch.zeros(S, device=device)\n",
    "                count_state  = torch.zeros(S, device=device)\n",
    "\n",
    "            # True totals\n",
    "            y_true_raw = (y_resid_true + baseline_full) * case_scale  # (S, H, V)\n",
    "            y_true_total = y_true_raw.sum(dim=2)                      # (S, H)\n",
    "\n",
    "            T_in, S2, F_macro = X_state_seq.shape\n",
    "            assert S2 == S\n",
    "\n",
    "            # Last observed per-variant daily counts\n",
    "            last_state = X_state_seq[-1]                             # (S, F_macro)\n",
    "            last_targets = last_state[:, target_variant_indices]     # (S, V)\n",
    "            last_targets_raw = last_targets * case_scale             # (S, V)\n",
    "\n",
    "            # Total last-value per state\n",
    "            last_total = last_targets_raw.sum(dim=1)                 # (S,)\n",
    "\n",
    "            # Repeat across horizon\n",
    "            y_hat_total = last_total.unsqueeze(1).expand(S, H)       # (S, H)\n",
    "\n",
    "            diff = y_hat_total - y_true_total\n",
    "            se = diff ** 2\n",
    "\n",
    "            sum_sq_state += se.sum(dim=1)\n",
    "            count_state  += H\n",
    "\n",
    "    rmse_state = torch.sqrt(sum_sq_state / count_state.clamp(min=1)).cpu().numpy()\n",
    "    return rmse_state\n"
   ],
   "id": "fea4ecc7ae7c8164",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:08:15.535845Z",
     "start_time": "2025-11-14T11:07:31.132158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "case_scale=1000\n",
    "rmse_model_day = rmse_by_day_model(model, val_loader, device, case_scale=case_scale)\n",
    "rmse_ma_day    = rmse_by_day_ma_baseline(val_loader, device, case_scale=case_scale)\n",
    "rmse_last_day  = rmse_by_day_last_value_baseline_from_residual(\n",
    "    val_loader, device, target_variant_indices, case_scale=case_scale\n",
    ")\n",
    "\n",
    "for d in range(len(rmse_model_day)):\n",
    "    print(\n",
    "        f\"Day {d+1}: model={rmse_model_day[d]:7.2f}, \"\n",
    "        f\"MA={rmse_ma_day[d]:7.2f}, \"\n",
    "        f\"last={rmse_last_day[d]:7.2f}\"\n",
    "    )\n",
    "rmse_model_global = overall_rmse_model_from_residual(model, val_loader, device, case_scale)\n",
    "rmse_ma_global    = overall_rmse_ma_baseline_from_residual(val_loader, device, case_scale)\n",
    "rmse_last_global  = overall_rmse_last_value_baseline_from_residual(\n",
    "    val_loader, device, target_variant_indices, case_scale\n",
    ")\n",
    "\n",
    "print(\"Global RMSE (model):      \", rmse_model_global)\n",
    "print(\"Global RMSE (MA baseline):\", rmse_ma_global)\n",
    "print(\"Global RMSE (last value): \", rmse_last_global)\n"
   ],
   "id": "3f12d9a8ff863e15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1: model= 723.30, MA=1024.32, last=1528.55\n",
      "Day 2: model= 752.84, MA=1015.24, last=1560.28\n",
      "Day 3: model= 714.74, MA=1014.22, last=1492.44\n",
      "Day 4: model= 762.93, MA=1015.57, last=1495.43\n",
      "Day 5: model= 715.68, MA=1018.60, last=1559.44\n",
      "Day 6: model= 727.88, MA=1007.76, last=1503.08\n",
      "Day 7: model= 694.57, MA=1000.90, last= 646.39\n",
      "Global RMSE (model):       727.74196639087\n",
      "Global RMSE (MA baseline): 1013.8242516281312\n",
      "Global RMSE (last value):  1431.4600919432226\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:22:37.425152Z",
     "start_time": "2025-11-14T11:22:14.057050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_cases = 100\n",
    "\n",
    "mape_model = overall_mape_model_from_residual(model, val_loader, device, case_scale, min_cases)\n",
    "mape_ma    = overall_mape_ma_baseline_from_residual(val_loader, device, case_scale, min_cases)\n",
    "mape_last  = overall_mape_last_value_baseline_from_residual(val_loader, device, target_variant_indices, case_scale, min_cases)\n",
    "\n",
    "print(f\"MAPE Thresholded at {min_cases} (model):      \", mape_model)\n",
    "print(f\"MAPE Thresholded at {min_cases} (MA baseline):\", mape_ma)\n",
    "print(f\"MAPE Thresholded at {min_cases} (last value): \", mape_last)\n"
   ],
   "id": "45c81ccf77176ff3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE Thresholded at 100 (model):       79.32596404106931\n",
      "MAPE Thresholded at 100 (MA baseline): 76.62154538740546\n",
      "MAPE Thresholded at 100 (last value):  105.43070804415895\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:31:05.898183Z",
     "start_time": "2025-11-14T11:30:36.552024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rmse_model_total = overall_rmse_model_total_from_residual(model, val_loader, device, case_scale)\n",
    "rmse_ma_total    = overall_rmse_ma_total_from_residual(val_loader, device, case_scale)\n",
    "rmse_last_total  = overall_rmse_last_total_from_residual(\n",
    "    val_loader, device, target_variant_indices, case_scale\n",
    ")\n",
    "\n",
    "print(\"Global RMSE on TOTAL cases (model):      \", rmse_model_total)\n",
    "print(\"Global RMSE on TOTAL cases (MA baseline):\", rmse_ma_total)\n",
    "print(\"Global RMSE on TOTAL cases (last value): \", rmse_last_total)\n"
   ],
   "id": "e9b7c8d229e6271e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global RMSE on TOTAL cases (model):       2123.238342545057\n",
      "Global RMSE on TOTAL cases (MA baseline): 2951.7399352207817\n",
      "Global RMSE on TOTAL cases (last value):  4158.839079426377\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:37:37.179532Z",
     "start_time": "2025-11-14T11:37:10.170044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rmse_model_state_total = rmse_by_state_total_model_from_residual(model, val_loader, device, case_scale)\n",
    "rmse_ma_state_total    = rmse_by_state_total_ma_from_residual(val_loader, device, case_scale)\n",
    "rmse_last_state_total  = rmse_by_state_total_last_from_residual(val_loader, device, target_variant_indices, case_scale)\n",
    "\n",
    "# If you have a list of state FIPS codes in the same order:\n",
    "for fips, r_model, r_ma, r_last in zip(state_fips_list, rmse_model_state_total,\n",
    "                                       rmse_ma_state_total, rmse_last_state_total):\n",
    "    print(f\"State {fips}: model={r_model:.1f}, MA={r_ma:.1f}, last={r_last:.1f}\")\n"
   ],
   "id": "fe36cdfaef37a356",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State 01: model=2085.4, MA=2222.8, last=3158.7\n",
      "State 04: model=1551.5, MA=3124.0, last=4442.6\n",
      "State 05: model=316.0, MA=255.3, last=340.7\n",
      "State 06: model=8635.8, MA=11589.1, last=16446.3\n",
      "State 08: model=720.4, MA=702.9, last=976.8\n",
      "State 09: model=505.2, MA=452.3, last=632.0\n",
      "State 10: model=247.6, MA=209.7, last=287.8\n",
      "State 11: model=202.7, MA=146.0, last=207.3\n",
      "State 12: model=6588.2, MA=6222.4, last=8396.5\n",
      "State 13: model=1977.9, MA=4042.3, last=5796.1\n",
      "State 16: model=362.3, MA=359.2, last=508.7\n",
      "State 17: model=1713.0, MA=2350.3, last=3317.7\n",
      "State 18: model=1517.5, MA=2194.6, last=3105.0\n",
      "State 19: model=689.5, MA=779.4, last=1101.9\n",
      "State 20: model=789.2, MA=1263.7, last=1799.7\n",
      "State 21: model=2105.0, MA=2960.9, last=4247.0\n",
      "State 22: model=2013.2, MA=2345.5, last=3217.2\n",
      "State 23: model=157.5, MA=161.3, last=224.1\n",
      "State 24: model=704.8, MA=766.1, last=1072.4\n",
      "State 25: model=1417.5, MA=3004.4, last=4232.7\n",
      "State 26: model=2587.6, MA=3749.6, last=5260.8\n",
      "State 27: model=1343.8, MA=2338.2, last=3321.0\n",
      "State 28: model=1008.1, MA=1183.3, last=1653.3\n",
      "State 29: model=1172.6, MA=1887.8, last=2721.2\n",
      "State 30: model=394.3, MA=385.1, last=562.3\n",
      "State 31: model=446.1, MA=443.4, last=621.1\n",
      "State 32: model=679.2, MA=697.8, last=975.7\n",
      "State 33: model=203.8, MA=190.1, last=265.2\n",
      "State 34: model=1411.3, MA=1441.3, last=1967.6\n",
      "State 35: model=413.1, MA=412.6, last=575.6\n",
      "State 36: model=2500.4, MA=2893.2, last=3946.4\n",
      "State 37: model=2530.0, MA=5768.7, last=8262.4\n",
      "State 38: model=294.1, MA=305.4, last=433.6\n",
      "State 39: model=2715.5, MA=5874.3, last=8347.6\n",
      "State 40: model=1107.8, MA=1526.6, last=2146.4\n",
      "State 41: model=787.7, MA=1124.6, last=1583.3\n",
      "State 42: model=2197.8, MA=4599.2, last=6480.4\n",
      "State 44: model=450.7, MA=557.7, last=788.4\n",
      "State 45: model=2376.2, MA=2822.8, last=4024.6\n",
      "State 46: model=334.5, MA=350.1, last=498.4\n",
      "State 47: model=2115.3, MA=2674.9, last=3694.3\n",
      "State 48: model=4319.0, MA=5889.9, last=8193.4\n",
      "State 49: model=912.9, MA=1051.4, last=1498.3\n",
      "State 50: model=176.9, MA=176.2, last=250.4\n",
      "State 51: model=903.8, MA=1310.4, last=1851.5\n",
      "State 53: model=1187.3, MA=1461.6, last=2080.0\n",
      "State 54: model=416.7, MA=431.7, last=611.1\n",
      "State 55: model=830.3, MA=1175.9, last=1671.2\n",
      "State 56: model=209.8, MA=200.8, last=290.1\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:47:26.142809Z",
     "start_time": "2025-11-14T11:47:26.127174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "beats_all = 0\n",
    "beats_ma = 0\n",
    "beats_last = 0\n",
    "for i, j, k in zip(rmse_model_state_total, rmse_ma_state_total, rmse_last_state_total):\n",
    "    if (i < j) and (i < k):\n",
    "        beats_all += 1\n",
    "        beats_ma += 1\n",
    "        beats_last += 1\n",
    "    elif i < j:\n",
    "        beats_ma += 1\n",
    "    elif i < k:\n",
    "        beats_last += 1\n",
    "beats_all/len(rmse_model_state_total), beats_ma/len(rmse_model_state_total), beats_last/len(rmse_model_state_total)"
   ],
   "id": "fd647499101386c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7346938775510204, 0.7346938775510204, 1.0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Global RMSE results\n",
    "GRU+GCN_Macro = 724, GRU = 807, GRU+GCN_Macro/Micro = 727"
   ],
   "id": "d97b03893e11655d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Eval per State (Rolling)",
   "id": "768f1d80f89d22cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:08:15.555947Z",
     "start_time": "2025-11-14T11:08:15.537860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def evaluate_per_state_rmse(model, loader, device, case_scale=1.0):\n",
    "#     \"\"\"\n",
    "#     Returns: rmse_per_state: np.ndarray of shape (S,)\n",
    "#     RMSE is computed over *all* windows, horizons, and output variants.\n",
    "#     If you trained on scaled cases, pass case_scale to get RMSE in original units.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     sum_sq = None   # will become tensor of shape (S,)\n",
    "#     count = 0       # total number of (horizon * v_out * num_windows)\n",
    "# \n",
    "#     with torch.no_grad():\n",
    "#         for X_state_seq, X_county_seq, y_true in loader:\n",
    "#             # remove batch dimension (batch_size=1)\n",
    "#             X_state_seq = X_state_seq.squeeze(0).to(device)    # (T_in, S, F_macro)\n",
    "#             X_county_seq = X_county_seq.squeeze(0).to(device)  # (T_in, M, F_micro)\n",
    "#             y_true = y_true.squeeze(0).to(device)              # (S, H, v_out)\n",
    "# \n",
    "#             y_pred = model(X_state_seq, X_county_seq)          # (S, H, v_out)\n",
    "# \n",
    "#             # Undo scaling if needed so RMSE is in original case units\n",
    "#             diff = (y_pred - y_true) * case_scale              # (S, H, v_out)\n",
    "# \n",
    "#             se = diff ** 2                                     # (S, H, v_out)\n",
    "#             # sum over horizon + variant dimensions -> per-state sum squared error\n",
    "#             se_per_state = se.sum(dim=(1, 2))                  # (S,)\n",
    "# \n",
    "#             if sum_sq is None:\n",
    "#                 sum_sq = se_per_state\n",
    "#             else:\n",
    "#                 sum_sq += se_per_state\n",
    "# \n",
    "#             # each window contributes H * v_out elements per state\n",
    "#             H = y_pred.shape[1]\n",
    "#             V = y_pred.shape[2]\n",
    "#             count += H * V\n",
    "# \n",
    "#     mse_per_state = sum_sq / count                             # (S,)\n",
    "#     rmse_per_state = torch.sqrt(mse_per_state)                 # (S,)\n",
    "# \n",
    "#     return rmse_per_state.cpu().numpy()\n",
    "# \n",
    "# def evaluate_last_value_baseline(loader, device, target_variant_indices, case_scale=1.0):\n",
    "#     \"\"\"\n",
    "#     Baseline: y_pred(s, h, v) = last observed value in the input window for that state & variant.\n",
    "#     Returns: rmse_per_state: np.ndarray of shape (S,)\n",
    "#     \"\"\"\n",
    "#     sum_sq = None\n",
    "#     count = 0\n",
    "#     target_variant_indices = torch.as_tensor(target_variant_indices, dtype=torch.long, device=device)\n",
    "# \n",
    "#     with torch.no_grad():\n",
    "#         for X_state_seq, X_county_seq, y_true in loader:\n",
    "#             # squeeze batch dim (batch_size = 1)\n",
    "#             X_state_seq = X_state_seq.squeeze(0).to(device)    # (T_in, S, F_macro)\n",
    "#             y_true = y_true.squeeze(0).to(device)              # (S, H, v_out)\n",
    "# \n",
    "#             T_in, S, F_macro = X_state_seq.shape\n",
    "#             H = y_true.shape[1]\n",
    "#             V = y_true.shape[2]\n",
    "# \n",
    "#             # last time step: (S, F_macro)\n",
    "#             last_state = X_state_seq[-1]                       # (S, F_macro)\n",
    "# \n",
    "#             # pick only target variants: (S, v_out)\n",
    "#             last_targets = last_state[:, target_variant_indices]   # (S, v_out)\n",
    "# \n",
    "#             # repeat across horizon: (S, H, v_out)\n",
    "#             y_pred = last_targets.unsqueeze(1).expand(S, H, V)\n",
    "# \n",
    "#             # undo scaling if needed\n",
    "#             diff = (y_pred - y_true) * case_scale              # (S, H, v_out)\n",
    "#             se = diff ** 2\n",
    "#             se_per_state = se.sum(dim=(1, 2))                  # (S,)\n",
    "# \n",
    "#             if sum_sq is None:\n",
    "#                 sum_sq = se_per_state\n",
    "#             else:\n",
    "#                 sum_sq += se_per_state\n",
    "# \n",
    "#             count += H * V\n",
    "# \n",
    "#     mse_per_state = sum_sq / count\n",
    "#     rmse_per_state = torch.sqrt(mse_per_state)\n",
    "#     return rmse_per_state.cpu().numpy()\n",
    "# \n",
    "# def evaluate_moving_average_baseline(loader, device, target_variant_indices, case_scale=1.0, K=7):\n",
    "#     \"\"\"\n",
    "#     Baseline: y_pred(s, h, v) = mean of last K days in the input window (per state & variant).\n",
    "#     Returns: rmse_per_state: np.ndarray of shape (S,)\n",
    "#     \"\"\"\n",
    "#     sum_sq = None\n",
    "#     count = 0\n",
    "#     target_variant_indices = torch.as_tensor(target_variant_indices, dtype=torch.long, device=device)\n",
    "# \n",
    "#     with torch.no_grad():\n",
    "#         for X_state_seq, X_county_seq, y_true in loader:\n",
    "#             X_state_seq = X_state_seq.squeeze(0).to(device)    # (T_in, S, F_macro)\n",
    "#             y_true = y_true.squeeze(0).to(device)              # (S, H, v_out)\n",
    "# \n",
    "#             T_in, S, F_macro = X_state_seq.shape\n",
    "#             H = y_true.shape[1]\n",
    "#             V = y_true.shape[2]\n",
    "# \n",
    "#             k = min(K, T_in)\n",
    "#             # last k days: (k, S, F_macro)\n",
    "#             last_k = X_state_seq[-k:]                          # (k, S, F_macro)\n",
    "# \n",
    "#             # mean over time: (S, F_macro)\n",
    "#             mean_state = last_k.mean(dim=0)\n",
    "# \n",
    "#             # pick only target variants: (S, v_out)\n",
    "#             mean_targets = mean_state[:, target_variant_indices]  # (S, v_out)\n",
    "# \n",
    "#             # repeat across horizon: (S, H, v_out)\n",
    "#             y_pred = mean_targets.unsqueeze(1).expand(S, H, V)\n",
    "# \n",
    "#             diff = (y_pred - y_true) * case_scale              # (S, H, v_out)\n",
    "#             se = diff ** 2\n",
    "#             se_per_state = se.sum(dim=(1, 2))                  # (S,)\n",
    "# \n",
    "#             if sum_sq is None:\n",
    "#                 sum_sq = se_per_state\n",
    "#             else:\n",
    "#                 sum_sq += se_per_state\n",
    "# \n",
    "#             count += H * V\n",
    "# \n",
    "#     mse_per_state = sum_sq / count\n",
    "#     rmse_per_state = torch.sqrt(mse_per_state)\n",
    "#     return rmse_per_state.cpu().numpy()\n",
    "# \n",
    "# def rmse_by_horizon_model(model, loader, device, case_scale=1.0):\n",
    "#     model.eval()\n",
    "#     sum_sq = None  # (H,)\n",
    "#     count = 0\n",
    "#     with torch.no_grad():\n",
    "#         for X_state_seq, X_county_seq, y_true in loader:\n",
    "#             X_state_seq = X_state_seq.squeeze(0).to(device)   # (T_in, S, F_macro)\n",
    "#             y_true = y_true.squeeze(0).to(device)             # (S, H, V)\n",
    "#             y_pred = model(X_state_seq, X_county_seq.squeeze(0).to(device)\n",
    "#                            if X_county_seq is not None else None)\n",
    "# \n",
    "#             diff = (y_pred - y_true) * case_scale             # (S, H, V)\n",
    "#             se = diff ** 2                                    # (S, H, V)\n",
    "#             se_h = se.sum(dim=(0, 2))                         # (H,)\n",
    "# \n",
    "#             if sum_sq is None:\n",
    "#                 sum_sq = se_h\n",
    "#             else:\n",
    "#                 sum_sq += se_h\n",
    "# \n",
    "#             S = y_true.shape[0]\n",
    "#             V = y_true.shape[2]\n",
    "#             count += S * V\n",
    "# \n",
    "#     mse_h = sum_sq / count                                    # (H,)\n",
    "#     return torch.sqrt(mse_h).cpu().numpy()                    # (H,)\n",
    "# \n",
    "# def rmse_by_horizon_last(loader, device, target_variant_indices, case_scale=1.0, K=7):\n",
    "#     target_variant_indices = torch.as_tensor(target_variant_indices, dtype=torch.long, device=device)\n",
    "#     sum_sq = None\n",
    "#     count = 0\n",
    "#     with torch.no_grad():\n",
    "#         for X_state_seq, X_county_seq, y_true in loader:\n",
    "#             X_state_seq = X_state_seq.squeeze(0).to(device)   # (T_in, S, F_macro)\n",
    "#             y_true = y_true.squeeze(0).to(device)             # (S, H, V)\n",
    "# \n",
    "#             T_in, S, F_macro = X_state_seq.shape\n",
    "#             H = y_true.shape[1]\n",
    "#             V = y_true.shape[2]\n",
    "# \n",
    "#             last_state = X_state_seq[-1]                      # (S, F_macro)\n",
    "#             last_targets = last_state[:, target_variant_indices]  # (S, V)\n",
    "#             y_pred = last_targets.unsqueeze(1).expand(S, H, V)\n",
    "# \n",
    "#             diff = (y_pred - y_true) * case_scale\n",
    "#             se = diff ** 2\n",
    "#             se_h = se.sum(dim=(0, 2))                         # (H,)\n",
    "# \n",
    "#             if sum_sq is None:\n",
    "#                 sum_sq = se_h\n",
    "#             else:\n",
    "#                 sum_sq += se_h\n",
    "# \n",
    "#             count += S * V\n",
    "# \n",
    "#     mse_h = sum_sq / count\n",
    "#     return torch.sqrt(mse_h).cpu().numpy()\n"
   ],
   "id": "89845592120eff14",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:08:15.576096Z",
     "start_time": "2025-11-14T11:08:15.557963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# case_scale = 1000.0  # or 1.0 if you didn't scale cases\n",
    "# device = next(model.parameters()).device\n",
    "# \n",
    "# # Model RMSE\n",
    "# rmse_model = evaluate_per_state_rmse(model, val_loader, device, case_scale=case_scale)\n",
    "# \n",
    "# # Baselines\n",
    "# rmse_last = evaluate_last_value_baseline(val_loader, device, target_variant_indices, case_scale=case_scale)\n",
    "# rmse_ma   = evaluate_moving_average_baseline(val_loader, device, target_variant_indices, case_scale=case_scale, K=7)\n",
    "# \n",
    "# print(\"Overall mean RMSE (model):      \", rmse_model.mean())\n",
    "# print(\"Overall mean RMSE (last value):\", rmse_last.mean())\n",
    "# print(\"Overall mean RMSE (7-day MA):  \", rmse_ma.mean())\n",
    "# \n",
    "# print(\"\\nPer-state comparison (first few):\")\n",
    "# for s_idx, s_fips in enumerate(state_fips_list[:10]):  # or all of them\n",
    "#     print(\n",
    "#         f\"State {s_fips}: \"\n",
    "#         f\"model={rmse_model[s_idx]:8.1f}, \"\n",
    "#         f\"last={rmse_last[s_idx]:8.1f}, \"\n",
    "#         f\"ma={rmse_ma[s_idx]:8.1f}\"\n",
    "#     )\n"
   ],
   "id": "a0ac01a7b02fa5f0",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:08:15.596215Z",
     "start_time": "2025-11-14T11:08:15.578113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rmse_h_model = rmse_by_horizon_model(model, val_loader, device, case_scale)\n",
    "# rmse_h_last  = rmse_by_horizon_last(val_loader, device, target_variant_indices, case_scale)\n",
    "# \n",
    "# for d in range(len(rmse_h_model)):\n",
    "#     print(f\"Day {d+1}: model={rmse_h_model[d]:.2f}, last={rmse_h_last[d]:.2f}\")\n"
   ],
   "id": "8dbb6379a3130496",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:08:15.616398Z",
     "start_time": "2025-11-14T11:08:15.598231Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e4c34c1d2e4ff6de",
   "outputs": [],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
